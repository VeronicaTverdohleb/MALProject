{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From feature engineering for Random Forest\n",
    "Base on the exploration done in section 3.6 Correlations between features, we decided to enrich the extracted features by adding color histograms and texture features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ResNet50 model with pretrained ImageNet weights\n",
    "feature_extractor = ResNet50(weights='imagenet', include_top=False, input_shape=(348, 348, 3), pooling='avg')\n",
    "\n",
    "def extract_color_histograms(image, bins=32, hist_range=(0, 1)):\n",
    "    histograms = [np.histogram(image[:, :, channel], bins=bins, range=hist_range)[0] for channel in range(3)]\n",
    "    return np.concatenate(histograms)\n",
    "\n",
    "def add_texture_features(image):\n",
    "    # Define the settings for local binary patterns\n",
    "    radius = 3\n",
    "    n_points = 8 * radius\n",
    "    method = 'uniform'\n",
    "    texture = local_binary_pattern(rgb2gray(image), n_points, radius, method)\n",
    "    return texture.ravel()  # Flatten the texture feature matrix to a vector\n",
    "\n",
    "def extract_features_and_labels(directory, image_size=(348, 348), batch_size=32, class_mode='categorical'):\n",
    "    datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=class_mode,  # This should be 'categorical' if you are using np.argmax\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Process each batch\n",
    "    for batch_imgs, batch_labels in generator:\n",
    "        # Extract features using ResNet50\n",
    "        cnn_features = feature_extractor.predict(batch_imgs)\n",
    "\n",
    "        # Extract color histograms and texture features\n",
    "        histograms = np.array([extract_color_histograms(img) for img in batch_imgs])\n",
    "        textures = np.array([add_texture_features(img) for img in batch_imgs])\n",
    "\n",
    "        # Combine CNN features with histograms and textures\n",
    "        combined_features = np.hstack([cnn_features, histograms, textures])\n",
    "\n",
    "        all_features.append(combined_features)\n",
    "        all_labels.append(batch_labels)\n",
    "\n",
    "        if len(all_features) * batch_size >= generator.samples:\n",
    "            break\n",
    "\n",
    "    return np.vstack(all_features), np.vstack(all_labels)  # Ensure labels are properly structured\n",
    "\n",
    "# Set class_mode to 'categorical' for one-hot encoding\n",
    "train_features_improved, train_labels_improved = extract_features_and_labels(\"GroceryStoreDataset-working/dataset/train\", class_mode='categorical')\n",
    "val_features_improved, val_labels_improved = extract_features_and_labels(\"GroceryStoreDataset-working/dataset/val\", class_mode='categorical')\n",
    "\n",
    "# Now you can use np.argmax since labels are one-hot encoded\n",
    "train_labels_improved = np.argmax(train_labels_improved, axis=1)\n",
    "val_labels_improved = np.argmax(val_labels_improved, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RandomForest classifier\n",
    "rf_model_improved = RandomForestClassifier(n_estimators=150)\n",
    "\n",
    "# Train the model once\n",
    "rf_model_improved.fit(train_features_improved, train_labels_improved)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "val_predictions_rf_improved = rf_model_improved.predict(val_features_improved)\n",
    "\n",
    "# Get the classification report\n",
    "classification_report_rf_improved = classification_report(val_labels_improved, val_predictions_rf_improved)\n",
    "\n",
    "# Print the classification report\n",
    "print(f\"Classification report:\\n{classification_report_rf_improved}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sadly, the adding texture and color information did not really improve the overall performance.\n",
    "\n",
    "This might be due to several factors:\n",
    "- Redundancy and Noise: The color histograms and texture features could be introducing redundancy or irrelevant information that confuses the model rather than helping it to generalize better. Deep learning models like ResNet50 are already proficient at capturing both low-level features (such as textures and colors) and high-level patterns in images. By adding extra features manually, you might be diluting the predictive power of the neural network features with less informative or noisy data.\n",
    "\n",
    "- Model Complexity and Overfitting: Adding more features increases the dimensionality of the input data. This higher dimensionality can lead to overfitting, especially if the number of training samples is not large enough to support the complexity of the model. Overfitting occurs when a model learns details and noise in the training data to the extent that it negatively impacts the performance of the model on new data.\n",
    "\n",
    "- Feature Scaling and Distribution: Even though tree-based models like RandomForest are generally not sensitive to the scale of features, the mixing of different types of features (deep features with manually extracted features) could lead to issues if these features differ significantly in their range and distribution. This disparity can bias the model to weigh some types of features more than others, potentially overshadowing useful signals with less relevant information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
